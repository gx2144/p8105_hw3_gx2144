---
title: "p8105_hw3_gx2144"
author: "Guangling Xu"
date: "10/4/2019"
output: github_document
---
## set up

```{r}
library(tidyverse)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")
```

## ggplot set
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

* Dataset Discription:

* There are 15 variables and 1,384,617 columns for each variable.Meanings of each variable are listed below: 

  * order_id: order identifier, to identify different orders.
  * product_id: product identifier, to identify different products in different aisles.
  * add_to_cart_order: order in which each product was added to cart.
  * reordered: 1 if this prodcut has been ordered by this user in the past, 0 otherwise.
  * user_id: customer identifier, to identify different users. In this dataset, there are 131,209 unique users.
  * eval_set: data for use in this class is exclusively from the “train” eval_set.
  * order_number: the order sequence number for this user (1 = first, n = nth).
  * order_dow: the day of the week on which the order was placed.
  * order_hour_of_day: the hour of the day on which the order was placed.
  * days_since_prior_order: days since the last order, capped at 30, NA if it was the first time being orderd.
  * product_name: name of the product.
  * aisle_id: aisle identifier,identify different aisles.
  * department_id: department identifier, identify different aisles.
  * aisle: the name of the aisle.
  * department: the name of the department.

* Use the 1st row as an example.The first order user:112108 bought was Bulgarian yogurt from yogurt aisle(id = 120) of dairy eggs department(id = 16). This product has been reorderd after 9 days of its last order at the 4th day of the week,10 am. The product id is 49302 and the order id is 1. 

```{r}
aislename = instacart %>% 
  select("aisle") %>% 
  distinct()  
nrow(aislename)

```
There are 134 aisles here.
```{r}  
mostorder = instacart %>%
  group_by(aisle) %>%
  count( name = "count") %>% 
  arrange(desc(count)) %>% 
  filter(count >= 10000)   
ggplot(mostorder,aes(x = aisle,y = count))+
  geom_point()+
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.5,
    vjust = 0.5))+
  ylim(5000,160000)
```
Most items ordered from the aisle is fresh vegetables.


```{r}
popbaking = instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popbaking = popbaking[c(1:3),]
knitr::kable(popbaking)
  
popdogfood = instacart %>% 
  filter(aisle == "dog food care") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popdogfood = popdogfood[c(1:3),]
knitr::kable(popdogfood)

popveg = instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popveg = popveg[c(1:3),]
knitr::kable(popveg)
```

* Three most popular products of baking ingredients aisle are Light Brown Sugar, Pure Baking Soda and Cane Sugar whose counts are 499,387 and 336.
* Three most popular products of dog food care are Snack Sticks Chicken & Rice Recipe Dog Treats, Organix Chicken & Brown Rice Recipe and Small Dog Biscuits whose counts are 30,28 and 26.
* Three most popular products of packaged vegetables fruits are Organic Baby Spinach, Organic Raspberries andOrganic Blueberriess whose counts are 9784,5546 and 4966.

```{r,warning=FALSE}
meanhour = instacart %>% 
   filter(product_name ==  c("Pink Lady Apples","Coffee Ice Cream")) %>%
   group_by(product_name,order_dow) %>% 
   summarize(
     meanhour = round(mean(order_hour_of_day),digit =2)) %>% 
   pivot_wider(
    names_from = order_dow,
    values_from = meanhour
  )

knitr::kable(meanhour)
```

* For Coffee Ice cream, mean hour of the day at which it has been ordered shows that mostly, it was ordered in the afternoon aroud 3pm.However, on the 5th and 6th day of the week, customers like to order around noon.
* For Pink Lady Apples, mean hour of the day at which it has been ordered shows that mostly, it was ordered around lunch time.


## Problem 2
## clean data
```{r}
brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health"& 
         response == c("Excellent","Fair","Good","Poor")) %>%    
  arrange(desc(response) ) 
```

```{r}
state2002 = brfss_smart2010 %>%
  select(year,locationabbr,locationdesc) %>% 
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  count(name = "count") %>% 
  filter(count >= 7) %>% 
  arrange(count)
```

* There are 7 state which were observed at 7 or more locations in 2002.They were CT,FL,RI,MA,PA,NV,NJ.NC and NJ were observed most, in which 10 locations have been observed.

```{r}
state2010 = brfss_smart2010 %>%
  select(year,locationabbr,locationdesc) %>% 
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  count(name = "count") %>% 
  filter(count >= 7) %>% 
  arrange(count)
```

* There are 11 state which were observed at 7 or more locations in 2002.They were CA,ME,OH,NV,ID,MA,NJ,TX,MD,PA,FL.FL were observed most, in which 48 locations have been observed.Compared to 2002,more states were observed and more locations were surveyed.And there were big differences between the choice of state where the survey was conducted.Changes between 2002 and 2010 reflect potential public health concerns given by the investigators.

```{r}
excellent = brfss_smart2010 %>%
  filter(response == "Excellent") %>% 
  select(year,locationabbr,locationdesc,data_value) %>% 
  group_by(year,locationabbr,locationdesc) %>% 
  summarise(meanvalue =round(mean(data_value),digit =2)) %>% 
  na.omit(meanvalue)  
  
ggplot(excellent,aes(x = year,y = meanvalue,color = locationabbr))+
    geom_point() + geom_line() + 
    theme(legend.position = "right")+       
    scale_y_continuous(breaks = seq(0,40,5))
 
```

* comment:


```{r}
NY = brfss_smart2010 %>%
  select(year,data_value,response,locationabbr,locationdesc) %>%
  arrange(year) %>% 
  filter(locationabbr == "NY"
         & (year == c("2006")|year == c("2010")) 
         ) %>% 
  select(-locationabbr)
ggplot(NY,aes(x = response,y = data_value,fill =locationdesc ))+
      geom_point() + 
      geom_line() + 
      geom_bar(stat = "identity" , position = "dodge",width = 0.4)+
      theme(legend.position = "right")+
      ggthemes::theme_excel()+
      scale_y_continuous(breaks = seq(0,30,2))+
      facet_grid(. ~ year)

 
```

* comment:

## problem 3
```{r}
options(digits=4)

accelerometer = read.csv("./accel_data.csv") %>% 
  na.omit() %>% 
  mutate(
    dayorweekends = recode(day,
      Friday = "weekdays",
      Thursday = "weekdays",
      Wednesday = "weekdays",
      Tuesday = "weekdays",
      Monday = "weekdays",
      Saturday = "weekdend",
      Sunday = "weekdend")
    ) %>% 
  select(dayorweekends,everything()) %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "activity",
    values_to = "activity count"
    
  )
  
```

* Descirption:
In this chart, column names are dayorweekends,week,day_id,day,activity and activity count. "dayorweekends" denotes whether the day is weekday or weekends;"week" denotes the nth week of the activity'"day_id" denotes the order of the day;"activity" denotes the time of the record in a day;"activity count" denotes the count of each activity.
Each day, there are 24*60 =1440 times of activity records and this record last for 5 weeks,equals to 35 days. So the sum of the acitivity counts is 50400, which is the same as the row number here.

```{r}
meanday = accelerometer %>% 
  group_by(day_id ) %>% 
  summarize(
    total = sum(`activity count`)
    )

knitr::kable(meanday)
```

* Based on the data, we can see that the sum of the activity count of a day periodically fluctuates.Once the sum is high, it goes down for a couple of days and then rises up again.

```{r}
hourcourse = accelerometer %>% 
  group_by(day_id,day) %>% 
  summarize(
    total = sum(`activity count`)
) %>% 
ggplot(aes(x = day_id,y = total))+
  geom_point()+
  geom_line(stat = "identity" ,aes(color = day))
hourcourse
```

* When we look at the smooth of the data, the trend goes like a curve. Overall, as days gone by, total activity count rised first and then decreased, then rised up or keep parallel to the x axis in the end. Among 7 days of week, Sunday and Saturday have unique curves which keep on decreasing over the days. This may imply that this patient used to relax and keep sedentary during weekends.





 



