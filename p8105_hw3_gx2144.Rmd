---
title: "p8105_hw3_gx2144"
author: "Guangling Xu"
date: "10/4/2019"
output: github_document
---
## set up

```{r, message=FALSE}
library(tidyverse)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")
```

## Problem 1

* Dataset Discription:

* There are 15 variables and 1,384,617 columns for each variable.Meanings of each variable are listed below: 

  * order_id: order identifier, to identify different orders.
  * product_id: product identifier, to identify different products in different aisles.
  * add_to_cart_order: order in which each product was added to cart.
  * reordered: 1 if this prodcut has been ordered by this user in the past, 0 otherwise.
  * user_id: customer identifier, to identify different users. In this dataset, there are 131,209 unique users.
  * eval_set: data for use in this class is exclusively from the “train” eval_set.
  * order_number: the order sequence number for this user (1 = first, n = nth).
  * order_dow: the day of the week on which the order was placed.
  * order_hour_of_day: the hour of the day on which the order was placed.
  * days_since_prior_order: days since the last order, capped at 30, NA if it was the first time being orderd.
  * product_name: name of the product.
  * aisle_id: aisle identifier,identify different aisles.
  * department_id: department identifier, identify different aisles.
  * aisle: the name of the aisle.
  * department: the name of the department.

* Use the 1st row as an example.The first order user:112108 bought was Bulgarian yogurt from yogurt aisle(id = 120) of dairy eggs department(id = 16). This product has been reorderd after 9 days of its last order at the 4th day of the week,10 am. The product id is 49302 and the order id is 1. 

## Format data
```{r}
instacart = instacart %>% 
  mutate(
    aisle = as.factor(aisle), 
    order_dow = recode(order_dow, 
                       "0" = "Sunday",
                       "1" = "Monday",
                       "2" = "Tuesday",
                       "3" = "Wedensday",
                       "4" = "Thursday",
                       "5" = "Friday",
                       "6" = "Saturday"),
    order_dow = as.factor(order_dow)
  
         )        
```

## Problem1

### count the aisle
```{r count the aisle and show the top1 aisle}
aislename = instacart %>% 
  select("aisle") %>% 
  distinct()  
nrow(aislename)

```

* There are 134 aisles here.

```{r show top aisles}
topaisle = instacart %>% 
  group_by(aisle) %>% 
  count( name = "count") %>% 
  arrange(desc(count)) %>% 
  head(n = 5L)  
knitr::kable(topaisle)
  
```

* The Top 5 aisles are fresh vegetables, fresh fruits, packaged vegetables fruits, yogurt and packaged cheese. 


### Number of items in each aisle

```{r}  
aislenumber = instacart %>% 
  count(aisle, name = "count") %>% 
  arrange(desc(count)) %>% 
  filter(count > 10000) %>% 
  mutate(
    rank = c(1:length(aisle)),
    aisle = fct_reorder(aisle , rank)
        ) 

ggplot(aislenumber,aes(x = rank,y = count, fill = aisle))+
  geom_bar(stat = "identity", width = 0.7)+
  labs(
    title = "number of order in each aisle plot",
    x = "rank of aisle ",
    y = "count of aisle"
  )+
  theme(
    legend.text = element_text( size = 7),
    legend.position = "bottom"
    )
  
```

* The aisle from which the items were ordered most is fresh vegetables.

### Three most popular items
```{r , message=FALSE}
popbaking = instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  select(aisle,product_name) %>% 
  group_by(aisle,product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popbaking = popbaking[c(1:3),]
  
popdogfood = instacart %>% 
  filter(aisle == "dog food care") %>% 
  select(aisle,product_name) %>% 
  group_by(aisle,product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popdogfood = popdogfood[c(1:3),]

popveg = instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  select(aisle,product_name) %>% 
  group_by(aisle,product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popveg = popveg[c(1:3),]

pop1 = full_join(popbaking,popdogfood)
pop2 = full_join(pop1,popveg)
knitr::kable(pop2)
```

* Three most popular products of baking ingredients aisle are Light Brown Sugar, Pure Baking Soda and Cane Sugar whose counts are 499,387 and 336.
* Three most popular products of dog food care are Snack Sticks Chicken & Rice Recipe Dog Treats, Organix Chicken & Brown Rice Recipe and Small Dog Biscuits whose counts are 30,28 and 26.
* Three most popular products of packaged vegetables fruits are Organic Baby Spinach, Organic Raspberries andOrganic Blueberriess whose counts are 9784,5546 and 4966.

### Apple and Ice Cream 
```{r,warning=FALSE}
meanhour = instacart %>% 
   filter(product_name ==  c("Pink Lady Apples","Coffee Ice Cream")) %>%
   group_by(product_name,order_dow) %>% 
   summarize(
     meanhour = round(mean(order_hour_of_day),digit =2)) %>% 
   pivot_wider(
    names_from = order_dow,
    values_from = meanhour
  ) 

knitr::kable(meanhour,digits = 0)
```

* For Coffee Ice cream, mean hour of the day at which it has been ordered shows that on weekdays, it was ordered in the afternoon aroud 3pm.However, on the weekends, customers like to order around noon. Friday is unique because on that day, the mean hour when the products were ordered was around 10am.
* For Pink Lady Apples, mean hour of the day at which it has been ordered shows that mostly, it was ordered around lunch time.


## Problem 2

### clean data
```{r}
brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>%
    separate(locationdesc, into = c("location" , "place"), sep = 4) %>% 
    select(year, locationabbr,  state = locationabbr, 
    place,response_value = data_value, -location, response, topic) %>% 
    filter(topic == "Overall Health"& 
           response %in% c("Excellent","Very good","Fair","Good","Poor")) %>%
  mutate(
    response = factor(response, 
    levels = c("Poor","Fair","Good","Very good","Excellent"))
         ) 
```

## States observed at 7 or more locations
```{r}
states = brfss_smart2010 %>%
  select(year,state,place,response) %>% 
  filter(year == "2002"| year == "2010") %>%
  group_by(year,state) %>% 
  summarize(
    count = n_distinct(place) 
    )%>% 
  filter(count >= 7) 
```

* There are only 6 states which were observed at 7 or more locations in 2002 which were CT,FL,MA,NC,NJ,PA.

* There are 14 states which were observed at 7 or more locations in 2010.They were CA,CO,FL,MA,MD,NC,NE,NJ,NY,OH,PA,SC,TX,WA.Compared to 2002,more states were observed and more locations were surveyed.And there were big differences between the choice of state where the survey was conducted.Changes between 2002 and 2010 reflect potential public health concerns given by the investigators.

```{r}
excellent = brfss_smart2010 %>%
  filter(response == "Excellent") %>% 
  select(year,state,response_value) %>% 
  group_by(year,state) %>% 
  summarise(meanvalue =round(mean(response_value),digit =2)) %>% 
  na.omit(meanvalue)  
  
ggplot(excellent,aes(x = year,y = meanvalue))+
    geom_line(aes(color = state)) + 
    theme_set(theme_minimal() + 
    theme(legend.position = "right"))+       
    scale_y_continuous(breaks = seq(0,40,5))
 
```

* We can see from this ""spaghetti"plot that the mean of the response_value flucuate with the years. The highest response is around 27 and the lowest response is around 15.


```{r}
NY = brfss_smart2010 %>%
  select(year,response_value,response,state,place) %>%
  filter(state == "NY",
        year == c("2006")|year == c("2010")
         ) %>% 
  select(-state)
ggplot(NY,aes(x = response,y = response_value,fill =place ))+
      geom_bar(stat = "identity" , position = "dodge",width = 0.8)+
      geom_line(aes(group = place , color = place))+
      geom_point(size = 1, alpha = 0.2)+
      theme(axis.text.x = element_text(size = 10, vjust = 0.5, hjust = 0.5, angle = 45))+
    theme(legend.position = "bottom")+
      facet_grid(. ~ year)

```

 * For Bronx county, the data was collected only in 2010 and the most response to their overall health is "Good".
 * For Erie County, data was collected in 2010 and most of them responsed as "Very Good".
 * For Kings County, people in 2006 thought their response to overall health is mostly "Good", but things changed in 2010. Most of them thought they have "Very good" response to their overall health status and only few of them responsed "poor".
 * For Monroe county, people's response to "Very Good" most .
 * For Nassau County, data in 2006 and 2010 shows that majority of them thought their ovrall health status is "Very Good". 
 * For people living in Queens County, their health status distribution remained the same over the years .
 * As for those living in Westchester County, their health status distribution remained the same over the years. Most of them responsed "Very Good".
 * As to Suffolk County, their health status distribution remained the same over the years.Most of them responsed "Very Good."

## problem 3
```{r data wrangling}
options(digits=0)

accelerometer = read.csv("./accel_data.csv") %>% 
  na.omit() %>% 
  mutate(week = as.factor(week),
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday",
   "Wednesday","Thursday", "Friday",    "Saturday")),
    dayorweekends = recode(day,
      Friday = "weekdays",
      Thursday = "weekdays",
      Wednesday = "weekdays",
      Tuesday = "weekdays",
      Monday = "weekdays",
      Saturday = "weekdend",
      Sunday = "weekdend"),
    
    ) %>% 
  select(dayorweekends,everything()) %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minutes",
    names_prefix = "activity.",
    values_to = "activity_count"
  ) %>% 
  mutate(
    minutes = as.numeric(minutes)
         )
  
```

* In this chart, column names are dayorweekends,week,day_id,day,minutes and activity count. "dayorweekends" denotes whether the day is weekday or weekends;"week" denotes the nth week of the activity'"day_id" denotes the order of the day;"minutes" denotes the time of the record in a day;"activity count" denotes the count of each activity.
Each day, there are 24*60 =1440 times of activity records and this record last for 5 weeks,equals to 35 days. So the sum of the acitivity counts is 50400, which is the same as the row number here.

### total activity over the day
```{r}
options(scipen = 10)
totalday = accelerometer %>% 
  group_by(week, day ) %>% 
  summarize(
    total = sum(activity_count)
    )

knitr::kable(totalday)
```

* Based on the data, we can see that the sum of the activity count of a day periodically fluctuates.Once the sum is high, it goes down for a couple of days and then rises up again. Also it seems like the patients does activities more on Sunday and Friday.

### inspection activity over the course of the day

```{r}
hourcourse = accelerometer %>% 
  group_by(day,minutes) %>% 
  summarize(mean = mean(activity_count)) 

ggplot(hourcourse,aes(x = minutes,y = mean, 
                      color= day))+
  geom_point(alpha = .5)+
  labs(
    title = "Activity over the course of the day",
    x = "hour of the day",
    y = "Mean activity value",
    color = "Day of the week") + 
  scale_x_continuous( breaks=seq(0，1440，60),
                      labels = c("0","1","2","3","4","5","6","7","8",
                      "9","10","11","12","13","14","15","16",
                      "17","18","19","20","21","22","23","24")
                      )+
  viridis::scale_color_viridis(
    discrete = TRUE
  )
  


```

* We can clearly see that this patients do more activity during the day and rest during the night, Also, we may conclude that this patient gets up at around 6:30 in the morning where the mean activity values are higher.Around 11:00am during the day, this patient did more activities which means that he may have lunch during this time period.Then around 8pm-9pm, the patient exercised more and then rested around 10pm at night.





 



