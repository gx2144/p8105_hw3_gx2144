---
title: "p8105_hw3_gx2144"
author: "Guangling Xu"
date: "10/4/2019"
output: github_document
---
## set up

```{r}
library(tidyverse)
library(p8105.datasets)
data("instacart")
data("brfss_smart2010")
```

## ggplot set
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1
```{r}
aislename = instacart %>% 
  select("aisle") %>% 
  distinct() %>% 
  nrow(aislename)

```
There are 134 aisles here.
```{r}  
mostorder = instacart %>%
  group_by(aisle) %>%
  count( name = "count") %>% 
  arrange(desc(count)) %>% 
  filter(count >= 10000)   
ggplot(mostorder,aes(x = aisle,y = count))+
  geom_point()+
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.5,
    vjust = 0.5))+
  ylim(5000,160000)



```
Most items ordered from the aisle is fresh vegetables.


```{r}
popbaking = instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popbaking = popbaking[c(1:3),]
knitr::kable(popbaking)
  
popdogfood = instacart %>% 
  filter(aisle == "dog food care") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popdogfood = popdogfood[c(1:3),]
knitr::kable(popdogfood)

popveg = instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  select(aisle,product_name) %>% 
  group_by(product_name) %>% 
  count(name = "count") %>% 
  arrange(desc(count)) 
popveg = popveg[c(1:3),]
knitr::kable(popveg)
```


```{r}

meanhour = instacart %>% 
   filter(product_name ==  c("Pink Lady Apples","Coffee Ice Cream")) %>%
   group_by(product_name,order_dow) %>% 
   summarize(
     meanhour = round(mean(order_hour_of_day),digit =2)) %>% 
   pivot_wider(
    names_from = order_dow,
    values_from = meanhour
  )
knitr::kable(meanhour)
 
  
```

 ## Problem 2
 ## clean data
```{r}
brfss_smart2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health"& 
         response == c("Excellent","Fair","Good","Poor")) %>%    
  arrange(desc(response) ) 
```

```{r}
state2002 = brfss_smart2010 %>%
  select(year,locationabbr,locationdesc) %>% 
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  count(name = "count") %>% 
  filter(count >= 7) %>% 
  arrange(count)
```

**There are 7 state which were observed at 7 or more locations in 2002.They were CT,FL,RI,MA,PA,NV,NJ.NC and NJ were observed most, in which 10 locations have been observed.

```{r}
state2010 = brfss_smart2010 %>%
  select(year,locationabbr,locationdesc) %>% 
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  count(name = "count") %>% 
  filter(count >= 7) %>% 
  arrange(count)
```

**There are 11 state which were observed at 7 or more locations in 2002.They were CA,ME,OH,NV,ID,MA,NJ,TX,MD,PA,FL.FL were observed most, in which 48 locations have been observed.Compared to 2002,more states were observed and more locations were surveyed.And there were big differences between the choice of state where the survey was conducted.Changes between 2002 and 2010 reflect potential public health concerns given by the investigators.

```{r}
excellent = brfss_smart2010 %>%
  filter(response == "Excellent") %>% 
  select(year,locationabbr,locationdesc,data_value) %>% 
  group_by(year,locationabbr,locationdesc) %>% 
  summarise(meanvalue =round(mean(data_value),digit =2)) %>% 
  na.omit(meanvalue)  
  
ggplot(excellent,aes(x = year,y = meanvalue,color = locationabbr))+
    geom_point() + geom_line() + 
    theme(legend.position = "right")+       
    scale_y_continuous(breaks = seq(0,40,5))

  
```
** comment:


```{r}
NY = brfss_smart2010 %>%
  select(year,data_value,response,locationabbr,locationdesc) %>%
  arrange(year) %>% 
  filter(locationabbr == "NY"
         & (year == c("2006")|year == c("2010")) 
         ) %>% 
  select(-locationabbr)
ggplot(NY,aes(x = response,y = data_value,fill =locationdesc ))+
      geom_point() + 
      geom_line() + 
      geom_bar(stat = "identity" , position = "dodge",width = 0.4)+
      theme(legend.position = "right")+
      ggthemes::theme_excel()+
      scale_y_continuous(breaks = seq(0,30,2))+
      facet_grid(. ~ year)

 
```
** comment:

## problem 3
```{r}
options(digits=4)

accelerometer = read.csv("./accel_data.csv") %>% 
  na.omit() %>% 
  mutate(
    dayorweekends = recode(day,
      Friday = "weekdays",
      Thursday = "weekdays",
      Wednesday = "weekdays",
      Tuesday = "weekdays",
      Monday = "weekdays",
      Saturday = "weekdend",
      Sunday = "weekdend")
    ) %>% 
  select(dayorweekends,everything()) %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "activity",
    values_to = "avtivity count"
    
  )
  
```
** Descirption:
In this chart, column names are dayorweekends,week,day_id,day,activity and activity count. "dayorweekends" denotes whether the day is weekday or weekends;"week" denotes the nth week of the activity'"day_id" denotes the order of the day;"activity" denotes the time of the record in a day;"activity count" denotes the count of each activity.
Each day, there are 24*60 =1440 times of activity records and this record last for 5 weeks,equals to 35 days. So the sum of the acitivity counts is 50400, which is the same as the row number here.

```{r}

```



 



